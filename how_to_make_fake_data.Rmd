---
title: "How to make fake data"
author: "M Santos Mira"
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  pdf_document:
    fig_caption: yes
---

# Introduction
Let's say we have an idea that egg volume varies between two different *Drosophila melanogaster* genotypes. How do we test this hypothesis with some degree of certainty? Maybe we can just place a bunch of females into a cage and collect random eggs? Would a more individual approach be better? After all, eggs aren't laid by the population, they are laid by each female, so maybe mother ID matters?  

What can we do to figure this out? Apart from actually putting a bunch of females into cages and putting some other females individually in petri dish and then compare which approach is better? Well, we can try to simulate both situations and compare which one would give us the best opportunity to see  (or not see) differences between genotypes.  

When doing regression analysis we have two main components: the effects we know, fixed effects which should be controlled in the experiment and random effects which are less "controlled" but can still be used in the analysis; and the "remaining variation", a residual variation which we don't know the origin. When introducing random effects, we're trying to explain some of those residuals as a random sample from a distribution (usually a normal distribution). So in a way, we end up with the same amount of error, $\varepsilon$, but it's split into two parts, the "explainable" part coming from random effects and the "leftover" part coming from residual variation.  

In this case, we are splitting the overall error from the population of eggs ($\varepsilon$) into the error from maternal effects ($\varepsilon_{M}$ - which tries to explain where the mean value of each mother will be) and into the error from each subpopulation of eggs ($\varepsilon_{E}$ - which tries to explain how far away from the respective mother each egg will be). The difference can be seen between \autoref{fig1} and \autoref{fig2}. In this case, the length of each line should be smaller when we add maternal ID as a random effect, meaning the unexplained part of the error will be lower and we'll understand how much of the "random processes" of determining egg volume are due to maternal effects (nutritional condition, for example).  

```{r fig1, echo = FALSE, out.width = "50%", fig.align="center", fig.cap = "\\label{fig1} Simulated value of eggs. Vertical lines represent the distance from each egg to the mean of the sample."}
library(knitr)
knitr::include_graphics("./sim_example_pop.png")
```


```{r fig2, echo = FALSE, out.width = "50%", fig.align="center", fig.cap = "\\label{fig2} Simulated value of eggs with highlighted maternal means. This graph contains the same points as Fig 1. Vertical lines represent the distance from each egg to the mean of it's respective mother. The horizontal dashed line represents the mean of the whole sample, already present in Figure 1 as a horizontal full line."}
knitr::include_graphics("./sim_example_mom.png")
```

With this established, we now have two questions:  

1) How important is maternal ID and how many eggs/mothers do we need to measure to understand if one level of the variability is really that different from the other?  
2) Which method is better to understand differences between genotypes? Should we collect from a cage with many mothers or measure individual mothers? And if in a cage how many eggs do we need to collect?

# Question 1 - How to test if maternal ID is important

## How to simulate data
To simulate data for this analysis we'll try to be as close to the biological reality as possible. First we can define some numbers based on biological meaning:  

```{r define_diffs, message = FALSE}
# set up packages and work directory
library(rethinking)
library(brms)
library(ggplot2)
library(cowplot)
setwd("~/Code/Rscripts")
set.seed(1234)

# constants for all simulations
egg_lambda <- 18.5
std_vol <- 8
std_sd <- 0.9

# variables we want to try
sd_diffs <- c(0.3, 0, -0.3)
vol_diffs <- c(0.5, 1, 2)
n_mothers <- c(10, 30, 60, 100)
n_eggs <- c(5, 10, 20)
n_eggs_cage <- c(50, 100)
```

So here we define 3 constants for all simulations: the rate at which mothers lay eggs (the $\lambda$ from a Poisson distributions - the rate of egg laying per 24h for example), a biologically realistic value for egg volume (in mm^3^ x 10^-3^) and a value for the standard deviation of egg volume taken from a pilot experiment. Next we define vectors for the variables we want to test with all the different values to be tested. In the order they were defined: the difference between the two levels of variability (maternal and egg, the scale of this difference comes from the same pilot experiment), the difference in volume of egg between different genotypes, the number of mothers to test (both in a cage and individually), the number of eggs to measure when testing individual females, and the number of eggs to measure when collecting from a egg laying cage.  

The next step is to loop through all the combinations of the variables we want. In this case, we'll use the sd_diffs, n_mothers and n_eggs vectors which amounts to `r length(sd_diffs) * length(n_mothers) * length(n_eggs)` different combinations (for now we'll ignore the vol_diffs vector but we'll return to in in question 2). After defining the 3 loops we start to think more biologically - for each mother, we will simulate an average volume. After we have an average volume for a specific mother, we simulate a volume for each egg. This applies two levels of randomness to our data - mothers have a random difference from the population mean volume (which we specified at the start as std_vol) and eggs have a random difference from the maternal mean volume.  

```{r first sim}
# to simulate we create a data.frame and then fill it with all the combination of the
# relevant parameters:
sim_maternal_effect <- data.frame(
  sd_diff = numeric(),
  n_mothers = numeric(),
  n_eggs = numeric(),
  mother_ID = numeric(),
  measure = numeric()
)

# simulate
# for each value of sd difference
for(i in 1:length(sd_diffs)){
  
  # for each number of eggs
  for(l in 1:length(n_eggs)){
    
    # for each number of mothers
    for(j in 1:length(n_mothers)){
      
      # for each mother on the respective number
      for(k in 1:n_mothers[j]){
        
        # each mother has its own mean value of volume which is
        mean_mother_k <- std_vol + rnorm(1, mean = 0, sd = std_sd - sd_diffs[i])
        
        # we make a temporary table to hold each mother's data
		    # (this is equal to the one we built before)
        temp_eggs <- data.frame(
          sd_diff = sd_diffs[i],
          n_mothers = n_mothers[j],
          n_eggs = n_eggs[l],
          mother_ID = k,
          measure = mean_mother_k + rnorm(n_eggs[l], mean = 0, sd = std_sd + sd_diffs[i])
        )
        
        # we add the temporary table to the end of the large data frame
        sim_maternal_effect <- rbind(sim_maternal_effect, temp_eggs)
      }
    }
  }
}
```

After this chunk of code we have all the data we need from our simulation. We have all possible combinations of sd differences, number of mother IDs, and number of collected eggs with random maternal errors and random egg errors.  

## Analysing simulated data

### Run statistical models

This next chunk makes sure we have the correct number of combinations before we run the statistical tests (which will try to recover the values we used to simulate).  

```{r prepare_anal_1}
# next we set up all combinations of parameters
reps <- length(sd_diffs) * length(n_mothers) * length(n_eggs)

rep_table <- as.data.frame(expand.grid(
  diff_values = sd_diffs,
  n_mom_values = n_mothers,
  n_eggs_values = n_eggs
))

# and check if combinations are correctly set up
reps == nrow(rep_table)
```

It seems like it's correct so we'll make a list of objects in which to store our models. We then loop through all the combinations of variables and analyse each subset of our simulation data table.  

```{r m1, eval = FALSE}
# if so, build a list od models to store everything
models <- vector("list", length = reps)

# analyse each amount - takes a looong time
for(i in 1:length(models)){
  models[[i]] <- brm(
    measure ~ 1 + (1 | mother_ID),
    data = subset(sim_maternal_effect,
                  n_mothers == rep_table$n_mom_values[i] &
                    sd_diff == rep_table$diff_values[i] &
                    n_eggs == rep_table$n_eggs_values[i]),
    
    cores = 8,
    chains = 8,
    iter = 5000,
    warmup = 1000
  )
  
  print(paste("Now finished loop:", as.character(i), sep = " "))
}

# Save an object to a file
saveRDS(models, file = "sim_models_example_1.rds")
```

Since this takes a long while to run, we'll just load the already saved models from a file.  

```{r load_m1, message = FALSE}
models <- readRDS(file = "sim_models_example_1.rds")
```

### Extract results

The next step is to analyse the results we got from the statistical analysis. We can do this analytically but instead we'll build graphs because they're prettier! First we'll define a function to calculate the intraclass correlation coefficient - a value between 0 and 1 which indicates where most of the variability lies. Since there are fixed boundaries between 0 and 1, this value can be described as the proportion of the total variance that is explained by the difference between mother IDs.  

```{r ICC_func}
# function to calculate intraclass correlation coefficient
# ICC = var(between moms)/(var(between moms)+var(within moms))
ICC <- function(alpha, epsilon) {
  sig_u <- alpha^2
  sig_u/(sig_u+(epsilon)^2)
}
```

The next step is to build the results data table. In this case, we used Bayesian analysis (using the brms package) so our results will be in the form of posterior samples. So in the next code chunk we build an empty data frame and extract the posterior samples from each model - filling out all the other information, including ICC and differences between standard deviations and distance from the "theoretical" intercept we defined at the start.  

```{r extract_pos_1}
# making a data table for the output
sim_result <- data.frame(
  diff = numeric(),
  n_mom = numeric(),
  n_eggs = numeric(),
  sim_ICC = numeric(),
  sim_diff = numeric(),
  sim_int = numeric()
)

# filling the data frame
for(i in 1:length(models)){
  sd <- posterior_samples(models[i], pars = "sd_mother_ID__Intercept")
  sigma <- posterior_samples(models[i], pars = "sigma")
  interc <- posterior_samples(models[i], pars = "b_Intercept")
  diff <- rep_table$diff_values[i]
  n_mom <- rep_table$n_mom_values[i]
  n_egg <- rep_table$n_eggs_values[i]

  temp_diff <- data.frame(
    diff = diff,
    n_mom = n_mom,
    n_eggs = n_egg,
    sim_ICC = ICC(sd, sigma),
    sim_diff = (sigma - sd ),
    sim_int = std_vol - interc
  )
  
  colnames(temp_diff) <- c("diff", "n_mom", "n_eggs", "sim_ICC", "sim_diff", "sim_int")
  sim_result <- rbind(sim_result, temp_diff)
}
```

In the next section we summarize all this data in graphs.  

### Plot results

For each of the graphs we want to make, we'll build a summary data frame where we'll store stuff like means, "treatments", SEM and SD. After filling this data frame we store the graph as a variable (g1, g2 and g3) and plot them all together at the end. Next we have three different code chunks followed by a small one where we put everything together.  

```{r g1}
# plot differences between population sigma and mother sd
sim_result$comb <- paste(sim_result$diff, sim_result$n_eggs, sim_result$n_mom, sep = "")
treatments_summ <- unique(sim_result$comb)
summary <- data.frame(comb = treatments_summ,
                      diff = NA,
                      n_mom = NA,
                      n_eggs = NA,
                      mean = NA,
                      SEM = NA,
                      SD = NA,
                      UHPDI = NA,
                      LHPDI = NA,
                      highbound = NA,
                      lowbound = NA
)

for(i in 1:length(treatments_summ)){
  data_temp <- subset(sim_result, comb == summary$comb[i])
  summary$diff[i] <- ifelse(data_temp$diff[1] == 0.3, "Mom < Res",
							ifelse(data_temp$diff[1] == 0, "Mom = Res", "Mom > Res"))
  summary$n_mom[i] <- data_temp$n_mom[1]
  summary$n_eggs[i] <- data_temp$n_eggs[1]
  summary$mean[i] <- mean(data_temp$sim_diff, na.rm = TRUE)
  summary$SEM[i] <-sd(data_temp$sim_diff, na.rm = TRUE) /
    sqrt(length(data_temp$sim_diff))
  summary$SD[i] <- sd(data_temp$sim_diff, na.rm = TRUE)
  summary$UHPDI[i] <- rethinking::HPDI(data_temp$sim_diff, prob = 0.95)[2]
  summary$LHPDI[i] <- rethinking::HPDI(data_temp$sim_diff, prob = 0.95)[1]
  summary$highbound[i] <- summary$UHPDI[i] - summary$mean[i]
  summary$lowbound[i] <- summary$mean[i] - summary$LHPDI[i]
}

g1 <- ggplot(data = summary, aes(x = n_mom,
                                 y = mean,
                                 colour = as.factor(diff),
                                 shape = as.factor(n_eggs),
                                 linetype = as.factor(diff))) +
  geom_point(position = position_dodge(width = 10), size = 2) +
  geom_errorbar(aes(ymin = mean - lowbound,
                    ymax = mean + highbound), width = 0.3,
                position = position_dodge(width = 10)) +
  geom_line(position = position_dodge(width = 10)) +
  ylab("Sigma diff") +
  xlab("Number of mothers") +
  scale_colour_discrete(name = "Relationship") +
  scale_linetype_discrete(name = "Relationship") +
  scale_shape_discrete(name = "Eggs collected") +
  geom_hline(yintercept = sd_diffs[1] * 2) +
  geom_hline(yintercept = sd_diffs[2] * 2) +
  geom_hline(yintercept = sd_diffs[3] * 2) +
  scale_x_continuous(breaks = n_mothers)
```

```{r g2}

# plotting ICC (intraclass correlation coefficient)
summary_ICC <- data.frame(comb = treatments_summ,
                          diff = NA,
                          n_mom = NA,
                          n_eggs = NA,
                          mean = NA,
                          SEM = NA,
                          SD = NA,
                          UHPDI = NA,
                          LHPDI = NA,
                          highbound = NA,
                          lowbound = NA
)

for(i in 1:length(treatments_summ)){
  data_temp <- subset(sim_result, comb == summary_ICC$comb[i])
  summary_ICC$diff[i] <- ifelse(data_temp$diff[1] == 0.3, "Mom < Res",
								ifelse(data_temp$diff[1] == 0, "Mom = Res", "Mom > Res"))
  summary_ICC$n_mom[i] <- data_temp$n_mom[1]
  summary_ICC$n_eggs[i] <- data_temp$n_eggs[1]
  summary_ICC$mean[i] <- mean(data_temp$sim_ICC, na.rm = TRUE)
  summary_ICC$SEM[i] <-sd(data_temp$sim_ICC, na.rm = TRUE) /
    sqrt(length(data_temp$sim_ICC))
  summary_ICC$SD[i] <- sd(data_temp$sim_ICC, na.rm = TRUE)
  summary_ICC$UHPDI[i] <- HPDI(data_temp$sim_ICC, prob = 0.95)[2]
  summary_ICC$LHPDI[i] <- HPDI(data_temp$sim_ICC, prob = 0.95)[1]
  summary_ICC$highbound[i] <- summary_ICC$UHPDI[i] - summary_ICC$mean[i]
  summary_ICC$lowbound[i] <- summary_ICC$mean[i] - summary_ICC$LHPDI[i]
}

g2 <- ggplot(data = summary_ICC, aes(x = n_mom,
                                     y = mean,
                                     colour = as.factor(diff),
                                     shape = as.factor(n_eggs),
                                     linetype = as.factor(diff))) +
  geom_point(position = position_dodge(width = 10)) +
  geom_errorbar(aes(ymin = mean - lowbound,
                    ymax = mean + highbound),
                width = 0.3,
                position = position_dodge(width = 10)) +
  geom_line(position = position_dodge(width = 10)) + 
  ylab("ICC") +
  xlab("Number of mothers") +
  scale_colour_discrete(name = "Relationship") +
  scale_linetype_discrete(name = "Relationship") +
  scale_shape_discrete(name = "Eggs collected") +
  geom_hline(yintercept = 0.5) +
  scale_x_continuous(breaks = n_mothers)

```

```{r g3}

# plot differences between seed intercept and simulated output
summary_int <- data.frame(comb = treatments_summ,
                          diff = NA,
                          n_mom = NA,
                          n_eggs = NA,
                          mean = NA,
                          SEM = NA,
                          SD = NA,
                          UHPDI = NA,
                          LHPDI = NA,
                          highbound = NA,
                          lowbound = NA
)

for(i in 1:length(treatments_summ)){
  data_temp <- subset(sim_result, comb == summary_int$comb[i])
  summary_int$diff[i] <- ifelse(data_temp$diff[1] == 0.3, "Mom < Res",
								ifelse(data_temp$diff[1] == 0, "Mom = Res", "Mom > Res"))
  summary_int$n_mom[i] <- data_temp$n_mom[1]
  summary_int$n_eggs[i] <- data_temp$n_eggs[1]
  summary_int$mean[i] <- mean(data_temp$sim_int, na.rm = TRUE)
  summary_int$SEM[i] <-sd(data_temp$sim_int, na.rm = TRUE) /
    sqrt(length(data_temp$sim_int))
  summary_int$SD[i] <- sd(data_temp$sim_int, na.rm = TRUE)
  summary_int$UHPDI[i] <- HPDI(data_temp$sim_int, prob = 0.95)[2]
  summary_int$LHPDI[i] <- HPDI(data_temp$sim_int, prob = 0.95)[1]
  summary_int$highbound[i] <- summary_int$UHPDI[i] - summary_int$mean[i]
  summary_int$lowbound[i] <- summary_int$mean[i] - summary_int$LHPDI[i]
}

g3 <- ggplot(data = summary_int, aes(x = n_mom,
                                     y = mean,
                                     colour = as.factor(diff),
                                     shape = as.factor(n_eggs),
                                     linetype = as.factor(diff))) +
  geom_point(position = position_dodge(width = 10)) +
  geom_errorbar(aes(ymin = mean - lowbound,
                    ymax = mean + highbound),
                width = 0.3,
                position = position_dodge(width = 10)) +
  geom_line(position = position_dodge(width = 10)) +
  ylab("Intercept diff") +
  xlab("Number of mothers") +
  scale_colour_discrete(name = "Relationship") +
  scale_linetype_discrete(name = "Relationship") +
  scale_shape_discrete(name = "Eggs collected") +
  geom_hline(yintercept = 0) +
  scale_x_continuous(breaks = n_mothers)
```

And we put everything together in \autoref{fig3}:

```{r gt, fig.width = 6, fig.height = 8, fig.cap = "\\label{fig3} Posterior sample means and HDPI at 95% for the analysis performed on simulated data. A) Standard deviation difference between the between and within mother levels of variation. B) Intraclass correlation coefficient (ICC) calculated using posterior samples. C) Differences between the estimations and the value used in the simulation for the intercept value. Horizontal black lines represent the values used for the simulation (A and C) or the point where both levels of variation are equal (B)."} 
plot_grid(g1, g2, g3, labels = c("A", "B", "C"), ncol = 1)
```

## Answering question 1

So how many mother IDs do we actually need to say if within mother variation is high or low relative to between mother variation? It seems that with 30 mothers we have already a relatively accurate estimate of differences between standard deviations. However, the uncertainty around these estimates is still relatively large (30 mothers, \autoref{fig3}). Here we simulated a difference between levels of 0.6, but if these differences were smaller we would have even less clear plots. We would have to collect data from 60 to 100 mothers to safely say that one level of variation is different from the other. Related to this, the difference between the theoretical intercept and the estimation is still very uncertain up to 60 mothers, especially when the between mother variation is larger than the within mother variation (\autoref{fig3}C, blue points).  

Regarding the number of eggs to collect per mother, it seems like there is no big difference between measuring 5, 10 or 20 eggs per mother as long as the number of mothers is high.  

So as an answer to question 1: to confidently say if there are differences between two levels of variation in egg volume we should measure 5 eggs from 100 different mothers.  

# Question 2 - Which method to tell differences

For question 2 we want to know what's the best way to test if there are any differences in egg volume between genotypes. Here we have two alternatives: collect egggs from a big pool of females or collect eggs from individual females. From \autoref{fig3}C, there already some hints that even if the averages between mothers are not very variable (that is, most variability comes from the differences between eggs) there is still a large uncertainty when trying to estimate the intercepts which indicates we might still need to test individual females. Bus let's test it. Here we will simulate two situations: a cage off egg laying where $n$ number of females will lay eggs (without a maximum number defined) and where we collect $x$ eggs, and collecting 10 eggs from $n$ females kept in individual enclosures. We can then compare these two situations and reach conclusions on which is the most time efficient.  

## Simulating data, again

Again we will generate $n$ number of individual mothers (10, 30, 60 or 100 as defined in the beginning of the document) and collect eggs from them. We also generate cages with the same $n$ mothers. However, in these cages, the mothers have a random number of eggs (defined at the start as a Poisson distribution with $\lambda = `r egg_lambda`$) and from the whole pool of eggs we collect either 50 or 100 eggs. We generate both sets of eggs the same way: mother's have an random average value and eggs have a random difference from that average. The aim here is, with the assumption that maternal effects are present, to figure out if extra work of collecting eggs from individual mothers is rewarded with a much higher accuracy.  

In this first code chunk, we create a data frame to store all simulated data and we generate it. First, the "bunched" data which comes from the egg laying cages, and second, the individual data. In the first case, we don't know which egg comes from which mother so we don't store this information.  

```{r bunched_sim}
# bulding data frame to store simulated data
sim_bunched <- data.frame(
  sd_diff = numeric(),
  vol_diffs = numeric(),
  n_eggs = numeric(),
  n_mothers = numeric(),
  maternal_effects = numeric(),
  mother_ID = numeric(),
  measure = numeric()
)

# these for-loops are to simulate cages
# for each standard deviation difference
for(i in 1:length(sd_diffs)){
  
  # for each difference in volume
  for(j in 1:length(vol_diffs)){
    
    # for each number of mothers (equivalent to different cages)
    for(k in 1:length(n_mothers)){
      
      # for each collection number
      for(l in 1:length(n_eggs_cage)){
        
        # building a vector to store all the eggs
        egg_cage <- vector()
        
        # for each mother in the group
        for(m in 1:n_mothers[k]){
          # number of eggs mother k lays
          laid_eggs <- rpois(1, lambda = egg_lambda)
          
	        # calculating a mean for mother m
	        mean_mother_m <- std_vol + vol_diffs[j] +
	          rnorm(1, mean = 0, sd = std_sd - sd_diffs[i])
	  
          # calculating the volume for each egg of this mother
          eggs_mother_k <- mean_mother_m +
            rnorm(laid_eggs, mean = 0, sd = std_sd + sd_diffs[i])
          
          # adding these eggs to the cage
          egg_cage <- c(egg_cage, eggs_mother_k)
        }
        
        sim_bunched_temp <- data.frame(
          sd_diff = sd_diffs[i],
          vol_diffs = vol_diffs[j],
          n_eggs_cage = n_eggs_cage[l],
          n_mothers = n_mothers[k],
          maternal_effects = F,
          mother_ID = NA,
          measure = sample(egg_cage, n_eggs_cage[l])
        )
        
        sim_bunched <- rbind(sim_bunched, sim_bunched_temp)
      }
    }
  }
}

# these for-loops are to simulate individual mothers
# for each standard deviation difference
for(i in 1:length(sd_diffs)){
  
  # for each difference in volume
  for(j in 1:length(vol_diffs)){
    
    # for each number of mothers (equivalent to different cages)
    for(k in 1:length(n_mothers)){
      
      # for each mother in the group
      for(m in 1:n_mothers[k]){
	
	    # calculating a mean for mother m
	    mean_mother_m <- std_vol + vol_diffs[j] +
	      rnorm(1, mean = 0, sd = std_sd - sd_diffs[i])

        # calculating the volume for each egg of this mother
        sim_bunched_temp <- data.frame(
          sd_diff = sd_diffs[i],
          vol_diffs = vol_diffs[j],
          n_eggs_cage = 10,
          n_mothers = n_mothers[k],
          maternal_effects = T,
          mother_ID = m,
          measure =
            mean_mother_m +
            rnorm(10, mean = 0, sd = std_sd + sd_diffs[i])
        )
        
        # adding these eggs to the pile
        sim_bunched <- rbind(sim_bunched, sim_bunched_temp)
      }
    }
  }
}
```

## Analysing simulated data

### Running statistical models

Following this we perform analysis on the simulated data again. For the two types of data collection we'll use different models. When we have maternal ID, we use a model with random effects and 3 different intercepts. When collecting from a cage we use a linear model with only 3 different intercepts without maternal random effects (because we don't have maternal information - they all laid eggs together).  

```{r model_2, eval = FALSE}
# next we set up all combinations of parameters
reps <- length(sd_diffs) * length(n_mothers) * length(n_eggs_cage)

rep_table <- as.data.frame(expand.grid(
  diff_values = sd_diffs,
  n_mom_values = n_mothers,
  n_eggs_values_cage = n_eggs_cage
))

# and check if combinations are correctly set up
reps == nrow(rep_table)

# if so, build a list od models to store everything
models2 <- vector("list", length = reps)

# analyse each amount - takes a looong time
for(i in 1:length(models2)){
  models2[[i]] <- brm(
    measure ~ as.factor(vol_diffs),
    data = subset(sim_bunched,
                  n_mothers == rep_table$n_mom_values[i] &
                    sd_diff == rep_table$diff_values[i] &
                    n_eggs_cage == rep_table$n_eggs_values[i] &
                    maternal_effects == FALSE),
    
    cores = 8,
    chains = 8,
    iter = 5000,
    warmup = 1000
  )
  
  print(paste("Now finished loop:", as.character(i), sep = " "))
}

# Save an object to a file
saveRDS(models2, file = "sim_models_example_2.rds")
```

```{r model_3, eval = FALSE}
# next we set up all combinations of parameters
reps_ME <- length(sd_diffs) * length(n_mothers)

rep_table_ME <- as.data.frame(expand.grid(
  diff_values_ME = sd_diffs,
  n_mom_values_ME = n_mothers
))

# and check if combinations are correctly set up
reps_ME == nrow(rep_table_ME)

# if so, build a list od models to store everything
models3 <- vector("list", length = reps_ME)

# analyse each amount - takes a looong time
for(i in 1:length(models3)){
  models3[[i]] <- brm(
    measure ~ as.factor(vol_diffs) + (1 | mother_ID),
    data = subset(sim_bunched,
                  n_mothers == rep_table_ME$n_mom_values[i] &
                    sd_diff == rep_table_ME$diff_values[i] &
                    maternal_effects == TRUE),
    
    cores = 8,
    chains = 8,
    iter = 5000,
    warmup = 1000,
    control = list(adapt_delta = 0.99)
  )
  
  print(paste("Now finished loop:", as.character(i), sep = " "))
}

# Save an object to a file
saveRDS(models3, file = "sim_models_example_3.rds")
```

Both take a long time to run so here we just load previously run models.  

```{r load_2_3}
# Restore the objects
models2 <- readRDS(file = "sim_models_example_2.rds")

models3 <- readRDS(file = "sim_models_example_3.rds")

# some vectors to use below (they weren't run on the previous blocks)
reps <- length(sd_diffs) * length(n_mothers) * length(n_eggs_cage)

rep_table <- as.data.frame(expand.grid(
  diff_values = sd_diffs,
  n_mom_values = n_mothers,
  n_eggs_values_cage = n_eggs_cage
))

reps_ME <- length(sd_diffs) * length(n_mothers)

rep_table_ME <- as.data.frame(expand.grid(
  diff_values_ME = sd_diffs,
  n_mom_values_ME = n_mothers
))

```

### Extract results

As before, we will extract the posterior samples from the models to plot.  

```{r extract_2_3}
# making a data table for the output
sim_result_2 <- data.frame(
  diff = numeric(),
  n_mom = numeric(),
  n_eggs = numeric(),
  vol_diffs = numeric(),
  ind_mothers = numeric(),
  sim_int = numeric()
)


for(i in 1:length(models2)){
  interc_0 <- posterior_samples(models2[i], pars = "b_Intercept")
  interc_1 <- interc_0 + posterior_samples(models2[i], pars = "b_as.factorvol_diffs1")
  interc_2 <- interc_0 + posterior_samples(models2[i], pars = "b_as.factorvol_diffs2")
  diff <- rep_table$diff_values[i]
  n_mom <- rep_table$n_mom_values[i]
  n_egg <- rep_table$n_eggs_values[i]
  vol_differences <- sort(rep(vol_diffs, length(interc_0[,1])))
  
  temp_diff <- data.frame(
    diff,
    n_mom,
    n_egg,
    vol_differences,
    ind_mothers = FALSE,
    rbind(interc_0, interc_1, interc_2)
  )
  
  colnames(temp_diff) <- c("diff", "n_mom", "n_eggs", "vol_diffs", "ind_mothers", "sim_int")
  sim_result_2 <- rbind(sim_result_2, temp_diff)
}

for(i in 1:length(models3)){
  interc_0 <- posterior_samples(models3[i], pars = "b_Intercept")
  interc_1 <- interc_0 + posterior_samples(models3[i], pars = "b_as.factorvol_diffs1")
  interc_2 <- interc_0 + posterior_samples(models3[i], pars = "b_as.factorvol_diffs2")
  diff <- rep_table_ME$diff_values_ME[i]
  n_mom <- rep_table_ME$n_mom_values_ME[i]
  n_egg <- 10
  vol_differences <- sort(rep(vol_diffs, length(interc_0[,1])))
  
  temp_diff <- data.frame(
    diff,
    n_mom,
    n_egg,
    vol_differences,
    ind_mothers = TRUE,
    rbind(interc_0, interc_1, interc_2)
  )
  
  colnames(temp_diff) <- c("diff", "n_mom", "n_eggs", "vol_diffs", "ind_mothers", "sim_int")
  sim_result_2 <- rbind(sim_result_2, temp_diff)
}
```

### Plotting the outcome

As we did above, we'll summarize the posterior distribution we obtained from the statistical models into a plot which will appear in \autoref{fig4}.  

```{r summ_2_3}

# plot differences between population sigma and mother sd
sim_result_2$comb <- paste(sim_result_2$diff,
                           sim_result_2$n_eggs,
                           sim_result_2$n_mom,
                           sim_result_2$vol_diffs,
                           sim_result_2$ind_mothers, sep = "")
treatments_summ <- unique(sim_result_2$comb)
summary <- data.frame(comb = treatments_summ,
                      diff = NA,
                      n_mom = NA,
                      n_eggs = NA,
                      vol_diffs = NA,
                      ind_mother = NA,
                      mean = NA,
                      SEM = NA,
                      SD = NA,
                      UHPDI = NA,
                      LHPDI = NA,
                      highbound = NA,
                      lowbound = NA
)

for(i in 1:length(treatments_summ)){
  data_temp <- subset(sim_result_2, comb == summary$comb[i])
  summary$diff[i] <- ifelse(data_temp$diff[1] == 0.3, "Mom < Res",
							ifelse(data_temp$diff[1] == 0, "Mom = Res", "Mom > Res"))
  summary$n_mom[i] <- data_temp$n_mom[1]
  summary$n_eggs[i] <- data_temp$n_eggs[1]
  summary$ind_mother[i] <-ifelse(data_temp$ind_mother[1] == T, "ME", "No ME")
  summary$vol_diffs[i] <- ifelse(data_temp$vol_diffs[1] == 0.5, "A",
								 ifelse(data_temp$vol_diffs[1] == 1, "B", "C"))
  summary$mean[i] <- mean(data_temp$sim_int, na.rm = TRUE)
  summary$SEM[i] <-sd(data_temp$sim_int, na.rm = TRUE) /
    sqrt(length(data_temp$sim_int))
  summary$SD[i] <- sd(data_temp$sim_int, na.rm = TRUE)
  summary$UHPDI[i] <- HPDI(data_temp$sim_int, prob = 0.95)[2]
  summary$LHPDI[i] <- HPDI(data_temp$sim_int, prob = 0.95)[1]
  summary$highbound[i] <- summary$UHPDI[i] - summary$mean[i]
  summary$lowbound[i] <- summary$mean[i] - summary$LHPDI[i]
}

hline_05 <- data.frame(
  diff = rep(c("Mom < Res", "Mom = Res", "Mom > Res"), 2),
  ind_mother = rep(c("ME", "No ME"), 3),
  five = 8.5,
  nine = 9,
  ten = 10
)

g4 <- ggplot(data = summary, aes(x = n_mom,
                                 y = mean,
                                 colour = as.factor(vol_diffs),
                                 shape = as.factor(n_eggs),
                                 linetype = as.factor(vol_diffs))) +
  geom_point(position = position_dodge(width = 10), size = 2) +
  geom_errorbar(aes(ymin = mean - lowbound,
                    ymax = mean + highbound), width = 0.3,
                position = position_dodge(width = 10)) +
  geom_line(position = position_dodge(width = 10)) +
  ylab("Volume") +
  xlab("Number of mothers") +
  scale_colour_discrete(name = "Treatment") +
  scale_linetype_discrete(name = "Treatment") +
  scale_shape_discrete(name = "Eggs collected") +
  geom_hline(data = hline_05, aes(yintercept = five)) +
  geom_hline(data = hline_05, aes(yintercept = nine)) +
  geom_hline(data = hline_05, aes(yintercept = ten)) +
  scale_x_continuous(breaks = n_mothers) +
  facet_grid(vars(as.factor(diff)), vars(as.factor(ind_mother)))
```

And we plot \autoref{fig4}:  

```{r , fig.width = 7, fig.height = 8, fig.cap = "\\label{fig4} Posterior sample means and HDPI at 95% for the analysis performed on simulated data. On the left we have data collected ffrom individual mothers and on the right we have data collected from a pool of multiple mothers. Top row is data generated with between mother variation smaller than within mother variation, middle row they are equal, and bottom row between mother variation is larger than within mother variation. Horizontal black lines represent the intercept values used for the simulation."}
g4
```

## Answering question 2

So which method is better? Pooled collection or an individual mother collection? It seems like it depends on the effect size. In this example, differences between treatment C and A are very apparent even with 10 mothers in a pooled condition(\autoref{fig4}). However, for the differences between treatment B and A, even after measuring 10 eggs from 100 different mothers from both conditions there is still some overlap (\autoref{fig4}).  

So which method is better? The individual sampling has a much higher level of accuracy. However it might be overkill, depending on the size of the differences being tested. Measuring 2000 eggs is a waste of time when we could have measured 200 and arrived at the same conclusion. But measuring 200 eggs and not having a conclusion is also a waste of time.  

# Final remarks

"All models are wrong, but some are useful" is an often used sentence in statistics. This can also be applied to simulations. What we did here is wrong. There is more to egg laying than a single average per genotype or per mother. But in some cases, these simplifications help us understand the problem and point us to some things we can correct and improve. In this case, it helped us understand that we might need a lot of mother IDs to have some certainty about between and within mother variability and that that number of measurements might be overkill when trying to differentiate between two genotypes. Taking a couple of hours to understand the problem and make up numbers will help in the long run!
